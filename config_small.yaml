# topâ€‘level device; e.g. "cuda" or "cpu"
device: &device cuda

###########################
### MODEL CONFIGURATION ###
###########################

model:
  from_raw_audio: true
  
  window_size: 6 # does not matter for training, since it is randomly selected to ensure generalization

  # common args for both encoder & decoder
  base_args:
    embed_dim: 128  # common embedding dimension for EnCodec: 128
    n_heads: 8
    n_layers: 8
    dim_feedforward: 512

  mae_args:
    embed_dim: 128 # common embedding dimension for EnCodec: 128
    n_heads: 8
    n_layers: 4
    dim_feedforward: 512

  # if you want to freeze patchify/unpatchify
  patchify_args:
    requires_grad: false
    device: *device
  
  unpatchify_args:
    requires_grad: false
    device: *device


###################################
### DISCRIMINATOR CONFIGURATION ###
###################################

discriminator:
  hop_lengths: [128, 256, 512]
  n_fft: [512, 1024, 2048]
  win_lengths: [512, 1024, 2048]
  n_mels: 64


################################
### DATALOADER CONFIGURATION ###
################################

dataloader:
  dataset_path: "../4060432"  # PATH TO THE DATASET DIRECTORY
  batch_size: 32
  train_subset_size: null # set to null to use the full dataset
  test_subset_size: null # set to null to use the full dataset
  num_workers: 0
  nsecs: 1.0 # desired length of the audios (in seconds) for trimming and padding audio samples
  shuffle: false

##############################
### TRAINING CONFIGURATION ###
##############################

training:
  num_epochs: 10000
  discriminator_train_freq: 1
  d_train_prob: 0.3333
  checkpoint_freq: 10
  eval_freq: 5
  start_checkpoint: 0
  writer_dir: runs/base_model
  checkpoint_dir: checkpoints/base_model

  lr_generator: 1.0e-4
  weight_decay: 1.0e-5

  lr_discriminator: 1.0e-7
  betas: [0.5, 0.9]

  lambdas :
    L_time: 1.0
    L_freq: 1.0
    L_adv: 3.0
    L_feat: 3.0
    L_mae: 0.1